"\"\"\"Streamlit dashboard for the wafer defect risk model.\"\"\""

from __future__ import annotations

from pathlib import Path
from typing import Optional, Dict, Any

import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import altair as alt
import numpy as np
import pandas as pd
import streamlit as st

from ml_pipeline import (
    ModelArtifacts,
    build_full_pipeline,
    compute_process_priority_scores,
    ensure_artifacts,
    load_artifacts,
    load_ontology,
)

ARTIFACT_DIR = Path("artifacts")


@st.cache_data(show_spinner=False)
def load_pipeline_outputs():
    """Run the preprocessing pipeline once and cache the results."""
    labelled_df, lot_df, prediction_dataset, priority_df = build_full_pipeline()
    return labelled_df, lot_df, prediction_dataset, priority_df


@st.cache_resource(show_spinner=False)
def load_ontology_data() -> Dict[str, Any]:
    """Load ontology metadata for process/zone/issue knowledge."""
    return load_ontology()


@st.cache_resource(show_spinner=False)
def load_trained_model() -> ModelArtifacts:
    """Load persisted model artifacts, training them if necessary."""
    try:
        return load_artifacts(ARTIFACT_DIR)
    except FileNotFoundError:
        artifacts, _, _ = ensure_artifacts(ARTIFACT_DIR)
        return artifacts


def _ensure_korean_font() -> None:
    """Register a font that supports Korean glyphs for Matplotlib."""
    if getattr(_ensure_korean_font, "_initialized", False):
        return

    font_candidates = [
        Path("/usr/share/fonts/truetype/nanum/NanumGothic.ttf"),
        Path("/usr/share/fonts/truetype/nanum/NanumGothicCoding.ttf"),
        Path("/usr/share/fonts/truetype/nanum/NanumMyeongjo.ttf"),
        Path("C:/Windows/Fonts/NanumGothic.ttf"),
        Path("C:/Windows/Fonts/NanumSquareR.ttf"),
        Path("C:/Windows/Fonts/malgun.ttf"),
        Path("C:/Windows/Fonts/Malgun.ttf"),
        Path("C:/Windows/Fonts/malgunbd.ttf"),
    ]

    selected_font = None
    for font_path in font_candidates:
        if font_path.exists():
            try:
                fm.fontManager.addfont(str(font_path))
                selected_font = fm.FontProperties(fname=str(font_path)).get_name()
                break
            except Exception:
                continue

    if selected_font:
        plt.rcParams["font.family"] = selected_font
    else:
        plt.rcParams["font.family"] = [
            "NanumGothic",
            "Malgun Gothic",
            "AppleGothic",
            "DejaVu Sans",
        ]

    plt.rcParams["axes.unicode_minus"] = False
    _ensure_korean_font._initialized = True


_ensure_korean_font()


def _build_ontology_maps(ontology: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:
    processes = ontology.get("processes", [])
    zones = ontology.get("spatial_zones", [])
    issues = ontology.get("issue_types", [])

    process_by_id = {proc.get("id"): proc for proc in processes if proc.get("id")}
    process_by_name = {proc.get("name"): proc for proc in processes if proc.get("name")}

    zone_by_id = {zone.get("id"): zone for zone in zones if zone.get("id")}
    zone_by_name = {zone.get("name"): zone for zone in zones if zone.get("name")}

    issue_by_id = {issue.get("id"): issue for issue in issues if issue.get("id")}
    issue_by_name = {issue.get("name"): issue for issue in issues if issue.get("name")}

    return {
        "process_by_id": process_by_id,
        "process_by_name": process_by_name,
        "zone_by_id": zone_by_id,
        "zone_by_name": zone_by_name,
        "issue_by_id": issue_by_id,
        "issue_by_name": issue_by_name,
    }


def _lookup_ontology_entry(
    maps: Dict[str, Dict[str, Any]],
    *,
    entry_id: Optional[str],
    entry_name: Optional[str],
    entry_type: str,
) -> Optional[Dict[str, Any]]:
    if entry_id and entry_id in maps[f"{entry_type}_by_id"]:
        return maps[f"{entry_type}_by_id"][entry_id]
    if entry_name and entry_name in maps[f"{entry_type}_by_name"]:
        return maps[f"{entry_type}_by_name"][entry_name]
    return None


def render_summary(
    prediction_dataset: pd.DataFrame,
    warning_threshold: float,
    severity_threshold: float,
) -> None:
    total_lots = prediction_dataset["Lot Name"].nunique()
    warned_lots = (
        prediction_dataset["Predicted_Risk"] >= warning_threshold
    ).sum()
    severity_series = prediction_dataset.get("Severity_Score")
    severity_hot_lots = (
        (prediction_dataset["Predicted_Risk"] >= warning_threshold)
        & (severity_series >= severity_threshold)
    ).sum()
    avg_risk = prediction_dataset["Total_Risk_Score"].mean()
    avg_severity = prediction_dataset["Severity_Score"].mean()
    metric_cols = st.columns(5)
    col1, col2, col3, col4, col5 = metric_cols
    col1.metric("Lot ìˆ˜", f"{total_lots:,}")
    col2.metric(
        "1ì°¨ ê²½ê³  Lot ìˆ˜",
        f"{warned_lots:,}",
        f"ì„ê³„ê°’ {warning_threshold:.2f}",
    )
    col3.metric(
        "2ì°¨ ê²½ê³  Lot ìˆ˜",
        f"{severity_hot_lots:,}",
        f"ì„ê³„ê°’ {severity_threshold:.2f}",
    )
    col4.metric(
        "í‰ê·  ìœ„í—˜ë„",
        f"{avg_risk:.2f}",
    )
    col5.metric(
        "í‰ê·  ì‹¬ê°ë„",
        f"{avg_severity:.2f}",
    )
    st.caption("ì„ê³„ê°’ì„ ì¡°ì •í•˜ë©´ ê²½ê³  Lot ìˆ˜ì™€ í‰ê·  ì§€í‘œê°€ ì¦‰ì‹œ ì—…ë°ì´íŠ¸ë©ë‹ˆë‹¤.")


def render_top_lots(
    top_df: pd.DataFrame,
    warning_threshold: float,
    severity_threshold: float,
) -> None:
    st.subheader("ìœ„í—˜ë„ ìƒìœ„ Lot")
    if top_df.empty:
        st.info("ìƒìœ„ Lot ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    top_df = top_df.copy()
    top_df["Risk_Gap"] = top_df["Predicted_Risk"] - top_df["Total_Risk_Score"]
    sort_order = top_df.sort_values("Predicted_Risk", ascending=False)["Lot Name"].tolist()

    base = alt.Chart(top_df).encode(
        y=alt.Y("Lot Name:N", sort=sort_order, title="Lot Name"),
    )

    predicted_bars = base.mark_bar(color="#fb6a4a").encode(
        x=alt.X("Predicted_Risk:Q", title="ìœ„í—˜ë„"),
        tooltip=[
            alt.Tooltip("Lot Name", title="Lot"),
            alt.Tooltip("Predicted_Risk", title="ì˜ˆì¸¡ ìœ„í—˜ë„", format=".3f"),
            alt.Tooltip("Total_Risk_Score", title="ì‹¤ì œ ìœ„í—˜ë„", format=".3f"),
            alt.Tooltip("Risk_Gap", title="ì˜ˆì¸¡-ì‹¤ì œ ì°¨ì´", format="+.3f"),
            alt.Tooltip("Severity_Score", title="ì‹¬ê°ë„ ì ìˆ˜", format=".3f"),
            alt.Tooltip("Killer_Defect_Count", title="í‚¬ëŸ¬ ê²°í•¨ ìˆ˜"),
            alt.Tooltip("Total_Count", title="ì „ì²´ ê²°í•¨ ìˆ˜"),
            alt.Tooltip("Killer_Defect_Count_per_slot", title="í‚¬ëŸ¬/ìŠ¬ë¡¯", format=".1f"),
            alt.Tooltip("Nuisance_Count_per_slot", title="ì¼ë°˜/ìŠ¬ë¡¯", format=".1f"),
            alt.Tooltip("False_Defect_Count_per_slot", title="ê±°ì§“/ìŠ¬ë¡¯", format=".1f"),
            alt.Tooltip(
                "Killer_Defect_Proportion",
                title="í‚¬ëŸ¬ ê²°í•¨ ë¹„ìœ¨",
                format=".1%",
            ),
        ],
        color=alt.condition(
            alt.datum.Risk_Gap > 0,
            alt.value("#fb6a4a"),
            alt.value("#9ecae1"),
        ),
    )

    actual_mark = base.mark_tick(color="#2171b5", thickness=2, size=30).encode(
        x=alt.X("Total_Risk_Score:Q"),
        tooltip=[
            alt.Tooltip("Lot Name", title="Lot"),
            alt.Tooltip("Total_Risk_Score", title="ì‹¤ì œ ìœ„í—˜ë„", format=".3f"),
        ],
    )

    gap_labels = base.mark_text(
        align="left",
        dx=6,
        color="#424242",
        fontSize=11,
    ).encode(
        x="Predicted_Risk:Q",
        text=alt.Text("Risk_Gap:Q", format="+.3f"),
    )

    chart = (predicted_bars + actual_mark + gap_labels).properties(height=400)
    st.altair_chart(chart, width="stretch")
    st.caption(
        "ì£¼í™© ë§‰ëŒ€=ì˜ˆì¸¡ ìœ„í—˜ë„, íŒŒë€ í‘œì‹œ=ì‹¤ì œ ìœ„í—˜ë„, ìˆ«ì=ì˜ˆì¸¡-ì‹¤ì œ ì°¨ì´ì…ë‹ˆë‹¤. "
        "ì°¨ì´ê°€ í´ìˆ˜ë¡ ëª¨ë¸ê³¼ ì‹¤ì œ ê°„ ê²©ì°¨ê°€ í¬ë‹¤ëŠ” ëœ»ì…ë‹ˆë‹¤."
    )


def render_risk_quadrant(
    prediction_dataset: pd.DataFrame,
    *,
    size_metric: str = "Killer_Defect_Proportion",
) -> None:
    if prediction_dataset.empty:
        st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    mean_risk = prediction_dataset["Total_Risk_Score"].mean()
    mean_severity = prediction_dataset["Severity_Score"].mean()

    if size_metric not in prediction_dataset.columns:
        size_metric = "Killer_Defect_Proportion"

    size_titles = {
        "Killer_Defect_Proportion": "í‚¬ëŸ¬ ê²°í•¨ ë¹„ìœ¨",
        "Total_Count": "ì „ì²´ ê²°í•¨ ìˆ˜",
        "Killer_Defect_Count": "í‚¬ëŸ¬ ê²°í•¨ ìˆ˜",
        "Severity_Score": "ì‹¬ê°ë„ ì ìˆ˜",
    }
    size_title = size_titles.get(size_metric, size_metric)

    base_chart = (
        alt.Chart(prediction_dataset)
        .mark_circle()
        .encode(
            x=alt.X(
                "Total_Risk_Score:Q",
                title="ìœ„í—˜ë„ (Total_Risk_Score)",
            ),
            y=alt.Y(
                "Severity_Score:Q",
                title="ì‹¬ê°ë„ (Severity_Score)",
            ),
            size=alt.Size(
                f"{size_metric}:Q",
                title=size_title,
                scale=alt.Scale(
                    range=[60, 600] if size_metric != "Total_Count" else [80, 900]
                ),
                legend=None,
            ),
            color=alt.Color(
                "Predicted_Risk:Q",
                scale=alt.Scale(scheme="reds"),
                title="ì˜ˆì¸¡ ìœ„í—˜ë„",
            ),
            tooltip=[
                alt.Tooltip("Lot Name", title="Lot"),
                alt.Tooltip("Predicted_Risk", title="ì˜ˆì¸¡ ìœ„í—˜ë„", format=".3f"),
                alt.Tooltip("Total_Risk_Score", title="ìœ„í—˜ë„", format=".3f"),
                alt.Tooltip("Severity_Score", title="ì‹¬ê°ë„", format=".3f"),
                alt.Tooltip(size_metric, title=size_title, format=".3f"),
            ],
        )
        .properties(height=380)
    )

    mean_rules = (
        alt.Chart(pd.DataFrame({"x": [mean_risk], "y": [mean_severity]}))
        .mark_rule(strokeDash=[6, 6], color="gray")
        .encode(x="x:Q")
        + alt.Chart(pd.DataFrame({"x": [mean_risk], "y": [mean_severity]}))
        .mark_rule(strokeDash=[6, 6], color="gray")
        .encode(y="y:Q")
    )

    st.altair_chart((base_chart + mean_rules).interactive(), width="stretch")


def _render_process_warning_pie(
    prediction_df: pd.DataFrame,
    labelled_df: pd.DataFrame,
    *,
    lot_mask: pd.Series,
    title: str,
    caption: str,
    color_scheme: str = "category20c",
) -> None:
    warning_lots = prediction_df.loc[lot_mask, "Lot Name"]
    st.markdown(f"#### {title}")
    if warning_lots.empty:
        st.info("í•´ë‹¹ ê²½ê³  ì¡°ê±´ì„ ì¶©ì¡±í•˜ëŠ” Lotì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    step_df = (
        labelled_df[labelled_df["Lot Name"].isin(warning_lots)]
        .dropna(subset=["Step_desc"])
        .groupby("Step_desc")["Lot Name"]
        .nunique()
        .reset_index(name="Lot_Count")
    )
    if step_df.empty:
        st.info("ê³µì • ì •ë³´ê°€ ìˆëŠ” ê²½ê³  Lotì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    step_df["Percentage"] = step_df["Lot_Count"] / step_df["Lot_Count"].sum()
    chart = (
        alt.Chart(step_df)
        .mark_arc(innerRadius=60)
        .encode(
            theta=alt.Theta("Lot_Count:Q"),
            color=alt.Color(
                "Step_desc:N",
                legend=alt.Legend(title="ê³µì •"),
                scale=alt.Scale(scheme=color_scheme),
            ),
            tooltip=[
                alt.Tooltip("Step_desc", title="ê³µì •"),
                alt.Tooltip("Lot_Count", title="Lot ìˆ˜", format="d"),
                alt.Tooltip("Percentage", title="ë¹„ìœ¨", format=".1%"),
            ],
        )
        .properties(height=320)
    )
    st.altair_chart(chart, width="stretch")
    st.caption(caption)


def render_process_warning_overview(
    prediction_df: pd.DataFrame,
    labelled_df: pd.DataFrame,
    *,
    warning_threshold: float,
    severity_threshold: float,
) -> None:
    severity_series = prediction_df.get("Severity_Score")
    if severity_series is None:
        severity_series = pd.Series(0, index=prediction_df.index, dtype=float)

    primary_mask = prediction_df["Predicted_Risk"] >= warning_threshold
    secondary_mask = primary_mask & (severity_series >= severity_threshold)

    if not primary_mask.any():
        st.markdown("#### ê³µì •ë³„ ê²½ê³  Lot ë¶„í¬")
        st.info("í˜„ì¬ ì„¤ì •ëœ ì„ê³„ê°’ì„ ë§Œì¡±í•˜ëŠ” 1ì°¨ ê²½ê³  Lotì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    if not secondary_mask.any():
        col_primary = st.container()
        with col_primary:
            _render_process_warning_pie(
                prediction_df,
                labelled_df,
                lot_mask=primary_mask,
                title="ê³µì •ë³„ ê²½ê³  Lot ë¶„í¬ (1ì°¨)",
                caption="ì˜ˆì¸¡ ìœ„í—˜ë„ ì„ê³„ê°’ì„ ì´ˆê³¼í•œ Lotì„ ê³µì • ê¸°ì¤€ìœ¼ë¡œ ì§‘ê³„í–ˆìŠµë‹ˆë‹¤.",
                color_scheme="reds",
            )
        return

    col_primary, col_secondary = st.columns(2, gap="large")
    with col_primary:
        _render_process_warning_pie(
            prediction_df,
            labelled_df,
            lot_mask=primary_mask,
            title="ê³µì •ë³„ 1ì°¨ ê²½ê³  Lot",
            caption="ì˜ˆì¸¡ ìœ„í—˜ë„ ì„ê³„ê°’ì„ ì´ˆê³¼í•œ Lotì„ ê³µì • ê¸°ì¤€ìœ¼ë¡œ ì§‘ê³„í–ˆìŠµë‹ˆë‹¤.",
            color_scheme="reds",
        )
    with col_secondary:
        _render_process_warning_pie(
            prediction_df,
            labelled_df,
            lot_mask=secondary_mask,
            title="ê³µì •ë³„ 2ì°¨ ê²½ê³  Lot",
            caption="1ì°¨ ê²½ê³  ì¤‘ì—ì„œ ì‹¬ê°ë„ ì„ê³„ê°’ê¹Œì§€ ì´ˆê³¼í•œ Lotì…ë‹ˆë‹¤.",
            color_scheme="blues",
        )


def render_process_priority(
    priority_df: pd.DataFrame,
    ontology: Dict[str, Any],
    *,
    top_n: int = 12,
    hotspot_detail: Optional[pd.DataFrame] = None,
) -> None:
    st.markdown("#### ê³µì • ë¬¸ì œ ìš°ì„ ìˆœìœ„ (P-Score)")
    if priority_df.empty:
        st.info("ìš°ì„ ìˆœìœ„ ë°ì´í„°ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    display_df = priority_df.head(top_n).copy()
    ontology_maps = _build_ontology_maps(ontology)
    problem_options = display_df["Problem_Item"].tolist()
    selected_problem = st.selectbox(
        "ìš°ì„  í•´ê²°í•  ë¬¸ì œ í•­ëª© ì„ íƒ",
        problem_options,
        index=0 if problem_options else None,
    )

    display_df["Is_Selected"] = np.where(
        display_df["Problem_Item"] == selected_problem, "ì„ íƒ", "ê¸°íƒ€"
    )
    display_df["ì„ íƒ"] = np.where(
        display_df["Problem_Item"] == selected_problem, "â—", ""
    )

    chart = (
        alt.Chart(display_df)
        .mark_bar(color="#74add1", stroke="#225ea8")
        .encode(
            x=alt.X("P_Score:Q", title="P-Score (ìš°ì„ ìˆœìœ„ ì ìˆ˜)"),
            y=alt.Y(
                "Problem_Item:N",
                sort=display_df.sort_values("P_Score", ascending=False)["Problem_Item"],
                title="ë¬¸ì œ í•­ëª©",
            ),
            color=alt.Color(
                "Is_Selected:N",
                scale=alt.Scale(domain=["ê¸°íƒ€", "ì„ íƒ"], range=["#74add1", "#fb6a4a"]),
                legend=None,
            ),
            tooltip=[
                alt.Tooltip("Final_Rank", title="ìˆœìœ„"),
                alt.Tooltip("Process_Name", title="ê³µì •"),
                alt.Tooltip("Zone_Name", title="ì˜ì—­"),
                alt.Tooltip("IssueType_Name", title="ì´ìŠˆ ìœ í˜•"),
                alt.Tooltip("Problem_Item", title="í•­ëª©"),
                alt.Tooltip("Real_Ratio", title="REAL ë¹„ìœ¨", format=".1%"),
                alt.Tooltip("Rank_Score", title="ì¤‘ìš”ë„(C)"),
                alt.Tooltip("P_Score", title="P-Score", format=".2f"),
                alt.Tooltip("Sample_Size", title="ìƒ˜í”Œ ìˆ˜"),
                alt.Tooltip("Category", title="ë¶„ë¥˜"),
            ],
        )
        .properties(height=max(260, 24 * len(display_df)))
    )
    st.altair_chart(chart, width="stretch")

    if not selected_problem:
        return

    selected_row = display_df[display_df["Problem_Item"] == selected_problem].iloc[0]

    metrics_cols = st.columns(4)
    metrics_cols[0].metric("ìš°ì„ ìˆœìœ„", f"{int(selected_row['Final_Rank'])}")
    metrics_cols[1].metric(
        "P-Score",
        f"{selected_row['P_Score']:.2f}",
        help="Real_Ratio Ã— Rank_Score",
    )
    metrics_cols[2].metric(
        "REAL ë¹„ìœ¨",
        f"{selected_row['Real_Ratio']:.1%}",
    )
    metrics_cols[3].metric(
        "ìƒ˜í”Œ ìˆ˜",
        f"{int(selected_row['Sample_Size']):,}",
        help="í•´ë‹¹ í•­ëª©ì— í¬í•¨ëœ ê²°í•¨ ê°œìˆ˜",
    )

    process_info = _lookup_ontology_entry(
        ontology_maps,
        entry_id=selected_row.get("Process_Id"),
        entry_name=selected_row.get("Process_Name"),
        entry_type="process",
    )
    zone_info = _lookup_ontology_entry(
        ontology_maps,
        entry_id=selected_row.get("Zone_Id"),
        entry_name=selected_row.get("Zone_Name"),
        entry_type="zone",
    )
    issue_info = _lookup_ontology_entry(
        ontology_maps,
        entry_id=selected_row.get("IssueType_Id"),
        entry_name=selected_row.get("IssueType_Name"),
        entry_type="issue",
    )

    st.markdown("##### ì˜¨í†¨ë¡œì§€ ê¶Œê³  ë° ì§„ë‹¨ í¬ì¸íŠ¸")
    description_lines: list[str] = []
    if issue_info:
        issue_name = issue_info.get("name", selected_row.get("IssueType_Name", ""))
        issue_description = issue_info.get("description")
        description_lines.append(f"- **ì´ìŠˆ ìœ í˜•:** {issue_name}")
        if issue_description:
            description_lines.append(f"  - {issue_description}")
    if zone_info:
        zone_name = zone_info.get("name", selected_row.get("Zone_Name", ""))
        zone_description = zone_info.get("description")
        description_lines.append(f"- **ê³µê°„ ì˜ì—­:** {zone_name}")
        if zone_description:
            description_lines.append(f"  - {zone_description}")
        related_causes = zone_info.get("related_causes")
        if related_causes:
            description_lines.append("  - ê°€ëŠ¥í•œ ì›ì¸: " + ", ".join(related_causes))
    if process_info:
        proc_name = process_info.get("name", selected_row.get("Process_Name", ""))
        proc_desc = process_info.get("description")
        description_lines.append(f"- **ê³µì •:** {proc_name}")
        if proc_desc:
            description_lines.append(f"  - {proc_desc}")

    if description_lines:
        st.markdown("\n".join(description_lines))
    else:
        st.info("í•´ë‹¹ í•­ëª©ì— ëŒ€í•œ ì¶”ê°€ ì˜¨í†¨ë¡œì§€ ì„¤ëª…ì´ ì—†ìŠµë‹ˆë‹¤.")

    if issue_info and issue_info.get("recommended_initial_actions"):
        st.markdown("**ì¶”ì²œ ì´ˆê¸° ì¡°ì¹˜:**")
        action_lines = "\n".join(
            f"- {action}" for action in issue_info["recommended_initial_actions"]
        )
        st.markdown(action_lines)

    if process_info and process_info.get("critical_parameters"):
        st.markdown("**ê´€ì‹¬ ê³µì • íŒŒë¼ë¯¸í„°:**")
        st.markdown(
            "\n".join(f"- {param}" for param in process_info["critical_parameters"])
        )

    if selected_row["Sample_Size"] < 50:
        st.warning(
            "ìƒ˜í”Œ ìˆ˜ê°€ ì ì€ í•­ëª©ì…ë‹ˆë‹¤. í˜„ì¥ ë°ì´í„°ì™€ í•¨ê»˜ ì¶”ê°€ ê²€ì¦ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )

    detail_candidates: Optional[pd.DataFrame] = None
    if hotspot_detail is not None and not hotspot_detail.empty:
        detail_candidates = hotspot_detail.copy()
        step_mask = detail_candidates["Step_desc"] == selected_row["Step_desc"]
        zone_id = selected_row.get("Zone_Id")
        zone_name = selected_row.get("Zone_Name")
        zone_mask = pd.Series(True, index=detail_candidates.index)
        if zone_id is not None and pd.notna(zone_id):
            zone_mask = detail_candidates["Zone_Id"] == zone_id
        elif zone_name is not None and pd.notna(zone_name):
            zone_mask = detail_candidates["Zone_Name"] == zone_name
        detail_candidates = detail_candidates[step_mask & zone_mask]
        if not detail_candidates.empty:
            detail_candidates = detail_candidates.sort_values(
                "P_Score", ascending=False
            )

    with st.expander("ì„¸ë¶€ Hotspot (1Âµm ë‹¨ìœ„)", expanded=False):
        if detail_candidates is None or detail_candidates.empty:
            st.info("ì„ íƒí•œ ê³µì •ì— ëŒ€í•œ ë¯¸ì„¸ Hotspot ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.markdown(
                "ì„ íƒ ê³µì •ì—ì„œ ë°˜ë³µ ê²€ì¶œë˜ëŠ” ë¯¸ì„¸ ì˜ì—­ì…ë‹ˆë‹¤. "
                "ë°˜ê²½ êµ¬ê°„ì´ ì¢ì„ìˆ˜ë¡ íŠ¹ì • ì¥ë¹„/íŒ¨ìŠ¤ì—ì„œì˜ ì˜¤ì—¼ ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤."
            )
            st.dataframe(
                detail_candidates.head(30)[
                    [
                        "Problem_Item",
                        "Real_Ratio",
                        "Rank_Score",
                        "P_Score",
                        "Sample_Size",
                    ]
                ],
                hide_index=True,
                width="stretch",
            )

    st.dataframe(
        display_df[
            [
                "ì„ íƒ",
                "Final_Rank",
                "Process_Name",
                "Zone_Name",
                "IssueType_Name",
                "Problem_Item",
                "Real_Ratio",
                "Rank_Score",
                "P_Score",
                "Sample_Size",
                "Category",
            ]
        ],
        width="stretch",
        height=280,
        hide_index=True,
    )


def _prepare_wafer_map_data(lot_rows: pd.DataFrame) -> pd.DataFrame:
    data = lot_rows.copy()
    if data.empty or "RADIUS" not in data.columns or "ANGLE" not in data.columns:
        return data

    max_radius = data["RADIUS"].replace(0, np.nan).max()
    target_radius = 150000.0 if pd.notna(max_radius) and max_radius > 0 else 1.0
    if pd.notna(max_radius) and max_radius > 0:
        scale_factor = target_radius / max_radius
        data["radius_norm"] = (data["RADIUS"] * scale_factor) / target_radius
    else:
        data["radius_norm"] = data["RADIUS"] / target_radius
    data["theta"] = np.deg2rad(data["ANGLE"])
    data["x"] = data["radius_norm"] * np.cos(data["theta"])
    data["y"] = data["radius_norm"] * np.sin(data["theta"])

    def _categorize(row: pd.Series) -> str:
        if row.get("IS_DEFECT") == "FALSE":
            return "False Defect"
        if row.get("is_killer_defect", False):
            return "Killer Defect"
        return "Nuisance Defect"

    data["Defect_Category"] = data.apply(_categorize, axis=1)
    return data


def _render_wafer_map(
    lot_rows: pd.DataFrame,
    *,
    width: Optional[int] = None,
    height: int = 420,
) -> None:
    _ensure_korean_font()
    map_data = _prepare_wafer_map_data(lot_rows)
    if map_data.empty:
        st.info("ì›¨ì´í¼ë§µì„ ìƒì„±í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    colors = {
        "Killer Defect": "#d7191c",
        "Nuisance Defect": "#2b83ba",
        "False Defect": "#bdbdbd",
    }
    mapped_colors = map_data["Defect_Category"].map(colors).fillna("#999999")

    size_source = None
    for candidate in ["DEFECT_AREA", "SIZE_D", "SIZE_X"]:
        if candidate in map_data.columns:
            size_source = map_data[candidate].abs().replace(0, np.nan)
            break
    if size_source is None:
        sizes = np.full(len(map_data), 22.0)
    else:
        normalized = size_source / (size_source.max() + 1e-6)
        sizes = np.clip(24 + normalized * 96, 18, 110)

    distances = np.sqrt(map_data["x"] ** 2 + map_data["y"] ** 2)
    boundary_margin = np.clip(1.0 - distances, 0.05, 1.0)
    sizes = sizes * (boundary_margin ** 2)

    alpha_source = None
    for candidate in ["SNR_OFFSET_GL", "PATCHDEFECTSIGNAL"]:
        if candidate in map_data.columns:
            alpha_source = map_data[candidate]
            break
    if alpha_source is not None:
        alpha_norm = (alpha_source - alpha_source.min()) / (
            (alpha_source.max() - alpha_source.min()) + 1e-6
        )
        alphas = 0.3 + 0.7 * alpha_norm
    else:
        alphas = np.where(map_data["Defect_Category"] == "False Defect", 0.3, 0.8)

    figsize = (4.8, 4.8) if width is None else (width / 100, height / 100)
    fig, ax = plt.subplots(figsize=figsize, dpi=160)
    fig.patch.set_facecolor("white")
    ax.set_facecolor("#f8f9fb")

    scatter = ax.scatter(
        map_data["x"],
        map_data["y"],
        s=sizes,
        c=mapped_colors,
        alpha=np.clip(alphas, 0.1, 0.95),
        edgecolors="white",
        linewidths=0.3,
    )

    wafer_circle = plt.Circle((0, 0), 1.0, color="#757575", fill=False, linewidth=1.4)
    ax.add_patch(wafer_circle)

    zone_radii = [0.33, 0.66, 0.9]
    for radius in zone_radii:
        style = {"linestyle": "--", "linewidth": 0.6, "edgecolor": "#b0bec5"}
        if np.isclose(radius, 0.9):
            style.update({"linestyle": ":", "linewidth": 0.6})
        ring = plt.Circle((0, 0), radius, fill=False, **style)
        ax.add_patch(ring)

    radial_angles = np.linspace(0, 2 * np.pi, 12, endpoint=False)
    for angle in radial_angles:
        ax.plot(
            [0, np.cos(angle)],
            [0, np.sin(angle)],
            color="#cfd8dc",
            linewidth=0.5,
            alpha=0.7,
        )

    ax.set_xlim(-1.05, 1.05)
    ax.set_ylim(-1.05, 1.05)
    ax.set_aspect("equal", adjustable="box")
    ax.set_xticks([])
    ax.set_yticks([])
    ax.set_title("")
    for spine in ax.spines.values():
        spine.set_visible(False)
    ax.grid(False)

    ax.text(
        0,
        -1.08,
        "Inner / Middle / Outer ì˜ì—­ ê¸°ì¤€ì„ ì„ í‘œì‹œí–ˆìŠµë‹ˆë‹¤.",
        ha="center",
        va="top",
        fontsize=8.5,
        color="#607d8b",
    )

    handles = [
        plt.Line2D(
            [0],
            [0],
            marker="o",
            color="w",
            label=label,
            markerfacecolor=color,
            markersize=8,
        )
        for label, color in colors.items()
    ]
    ax.legend(
        handles=handles,
        loc="lower center",
        bbox_to_anchor=(0.5, 1.02),
        ncol=len(handles),
        title="ê²°í•¨ ìœ í˜•",
        frameon=False,
    )

    st.pyplot(fig, clear_figure=True)


def _pattern_summary(lot_rows: pd.DataFrame) -> pd.DataFrame:
    if lot_rows.empty:
        return pd.DataFrame()

    enriched = _prepare_wafer_map_data(lot_rows)
    grouped = (
        enriched.groupby(["Step_desc", "Class", "KMeans_Cluster", "Defect_Category"])
        .size()
        .reset_index(name="Count")
    )
    grouped["Proportion"] = grouped["Count"] / grouped["Count"].sum()
    grouped = grouped.sort_values(by="Count", ascending=False)
    return grouped


def render_lot_detail(
    prediction_dataset: pd.DataFrame,
    labelled_df: pd.DataFrame,
    warning_threshold: float,
    severity_threshold: float,
    selected_lot: str,
) -> None:
    st.subheader("Lot ìƒì„¸")
    if selected_lot not in prediction_dataset["Lot Name"].values:
        st.info("ì„ íƒí•œ Lot ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    lot_summary = prediction_dataset[
        prediction_dataset["Lot Name"] == selected_lot
    ].iloc[0]

    def _render_component_pie(
        data_map: dict[str, float],
        *,
        legend_title: str,
        color_scheme: str,
    ) -> None:
        filtered = [
            (label, float(value))
            for label, value in data_map.items()
            if pd.notna(value) and float(value) > 0
        ]
        total = sum(value for _, value in filtered)
        if total <= 0:
            st.info(f"{legend_title} ì •ë³´ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        pie_df = pd.DataFrame(filtered, columns=["Component", "Value"])
        pie_df["Percentage"] = pie_df["Value"] / total
        chart = (
            alt.Chart(pie_df)
            .mark_arc(innerRadius=40)
            .encode(
                theta=alt.Theta("Value:Q"),
                color=alt.Color(
                    "Component:N",
                    scale=alt.Scale(scheme=color_scheme),
                    legend=alt.Legend(title=legend_title),
                ),
                tooltip=[
                    alt.Tooltip("Component", title="êµ¬ì„± ìš”ì†Œ"),
                    alt.Tooltip("Value", title="ê°€ì¤‘ì¹˜", format=".3f"),
                    alt.Tooltip("Percentage", title="ë¹„ìœ¨", format=".1%"),
                ],
            )
            .properties(height=300)
        )
        st.altair_chart(chart, width="stretch")

    col1, col2, col3 = st.columns(3)
    col1.metric(
        "ì˜ˆì¸¡ ìœ„í—˜ë„",
        f"{lot_summary['Predicted_Risk']:.3f}",
        f"{lot_summary['Prediction_Error']:+.3f}",
    )
    col2.metric(
        "ì‹¤ì œ ìœ„í—˜ë„",
        f"{lot_summary['Total_Risk_Score']:.3f}",
    )
    col3.metric(
        "ì‹¬ê°ë„ ì ìˆ˜",
        f"{lot_summary.get('Severity_Score', 0):.3f}",
        f"{lot_summary['Killer_Defect_Proportion']:.1%}",
    )

    primary_warning = lot_summary["Predicted_Risk"] >= warning_threshold
    secondary_warning = lot_summary.get("Severity_Score", 0) >= severity_threshold
    warning_state: list[str] = []
    if primary_warning:
        warning_state.append("âš ï¸ 1ì°¨ ê²½ê³  (ìœ„í—˜ë„)")
    if secondary_warning:
        warning_state.append("ğŸ” 2ì°¨ ê²½ê³  (ì‹¬ê°ë„)")
    if warning_state:
        st.warning(" Â· ".join(warning_state))
    else:
        st.success("ê²½ê³  ì—†ìŒ")

    severity_components = {
        col.replace("Severity_Component_", "").replace("_", " "): lot_summary[col]
        for col in lot_summary.index
        if str(col).startswith("Severity_Component_")
    }
    risk_component_weights = {
        "Score_Killer": ("í‚¬ëŸ¬ ê²°í•¨ ê¸°ì—¬", 0.50),
        "Score_Nuisance": ("ì¼ë°˜ ê²°í•¨ ê¸°ì—¬", 0.30),
        "Score_False": ("ê±°ì§“ ê²°í•¨ ê¸°ì—¬", 0.20),
    }
    risk_components = {
        label: lot_summary.get(col, 0) * weight
        for col, (label, weight) in risk_component_weights.items()
    }

    chart_left, chart_right = st.columns(2)
    with chart_right:
        st.markdown("### Lot ì‹¬ê°ë„ êµ¬ì„±")
        _render_component_pie(
            severity_components,
            legend_title="ì‹¬ê°ë„ êµ¬ì„±",
            color_scheme="blues",
        )
    with chart_left:
        st.markdown("### Lot ìœ„í—˜ë„ êµ¬ì„±")
        _render_component_pie(
            risk_components,
            legend_title="ìœ„í—˜ë„ êµ¬ì„±",
            color_scheme="reds",
        )

    lot_rows = labelled_df[labelled_df["Lot Name"] == selected_lot].copy()

    with st.expander("ê²½ê³  ì„ê³„ê°’ ì„¤ì •", expanded=False):
        st.write(
            f"í˜„ì¬ 1ì°¨ ê²½ê³  ì„ê³„ê°’: **{warning_threshold:.2f}**, "
            f"2ì°¨ ê²½ê³  ì„ê³„ê°’: **{severity_threshold:.2f}**"
        )
        st.caption("ì‚¬ì´ë“œë°”ì—ì„œ ì„ê³„ê°’ì„ ì¡°ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    st.markdown("### ê²°í•¨ íŒ¨í„´ ìš”ì•½")
    pattern_df = _pattern_summary(lot_rows)
    if pattern_df.empty:
        st.info("íŒ¨í„´ ìš”ì•½ì„ ê³„ì‚°í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.dataframe(
            pattern_df,
            width="stretch",
            height=320,
        )

    st.markdown("### ê²°í•¨ ìƒì„¸ í…Œì´ë¸”")
    st.caption("í•„ìš” ì‹œ í•„í„° í›„ CSVë¡œ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
    st.dataframe(lot_rows, width="stretch", height=420)

    csv = lot_rows.to_csv(index=False).encode("utf-8")
    st.download_button(
        label="ê²°í•¨ ë°ì´í„° CSV ë‹¤ìš´ë¡œë“œ",
        data=csv,
        file_name=f"{selected_lot}_defects.csv",
        mime="text/csv",
    )


def main() -> None:
    st.set_page_config(
        page_title="Wafer Defect Risk Dashboard",
        layout="wide",
    )
    st.title("Wafer Defect Risk Dashboard")
    labelled_df, lot_df, prediction_dataset, priority_df = load_pipeline_outputs()
    ontology = load_ontology_data()
    artifacts = load_trained_model()

    prediction_dataset = prediction_dataset.copy()
    prediction_dataset["Predicted_Risk"] = artifacts.model.predict(
        prediction_dataset[artifacts.feature_names]
    )
    prediction_dataset["Prediction_Error"] = (
        prediction_dataset["Predicted_Risk"] - prediction_dataset["Total_Risk_Score"]
    )

    st.sidebar.header("ê²½ê³  Â· í•„í„°")
    warning_threshold = st.sidebar.slider(
        "1ì°¨ ê²½ê³  (ì˜ˆì¸¡ ìœ„í—˜ë„)",
        min_value=0.0,
        max_value=1.0,
        value=0.6,
        step=0.05,
    )
    severity_threshold = st.sidebar.slider(
        "2ì°¨ ê²½ê³  (ì‹¬ê°ë„ ì ìˆ˜)",
        min_value=0.0,
        max_value=1.0,
        value=0.5,
        step=0.05,
    )
    step_options = sorted(labelled_df["Step_desc"].dropna().unique().tolist())
    step_filter = st.sidebar.multiselect(
        "Step í•„í„°",
        options=step_options,
        default=[],
    )

    filtered_prediction = prediction_dataset.copy()
    filtered_labelled = labelled_df.copy()
    filtered_priority = priority_df.copy()
    lot_mask = set(filtered_prediction["Lot Name"])
    if step_filter:
        step_lots = set(
            filtered_labelled[filtered_labelled["Step_desc"].isin(step_filter)][
                "Lot Name"
            ]
        )
        lot_mask = lot_mask.intersection(step_lots)
        filtered_labelled = filtered_labelled[
            filtered_labelled["Step_desc"].isin(step_filter)
        ]
        filtered_priority = filtered_priority[
            filtered_priority["Process_Id"].isin(step_filter)
        ]
    if step_filter:
        filtered_prediction = filtered_prediction[
            filtered_prediction["Lot Name"].isin(lot_mask)
        ]

    summary_priority = compute_process_priority_scores(
        filtered_labelled,
        include_hotspots=False,
    )
    hotspot_detail = compute_process_priority_scores(
        filtered_labelled,
        include_hotspots=True,
        window_size=1.0,
        min_window_samples=5,
    )
    hotspot_detail = hotspot_detail[hotspot_detail["Category"] == "Hotspot"]
    if not summary_priority.empty:
        filtered_priority = summary_priority

    render_summary(filtered_prediction, warning_threshold, severity_threshold)
    render_process_warning_overview(
        filtered_prediction,
        filtered_labelled,
        warning_threshold=warning_threshold,
        severity_threshold=severity_threshold,
    )

    tabs = st.tabs(["Lot ê°œìš”", "Lot ìƒì„¸", "ê³µì • ì˜¨í†¨ë¡œì§€"])

    with tabs[0]:
        st.markdown("#### ìœ„í—˜ë„ ìƒìœ„ Lot")
        top_n = st.slider(
            "í‘œì‹œí•  ìƒìœ„ Lot ìˆ˜",
            min_value=5,
            max_value=30,
            value=10,
            step=5,
        )
        component_cols = [
            col
            for col in filtered_prediction.columns
            if col.startswith("Severity_Component_")
        ]
        per_slot_cols = [
            col
            for col in [
                "Killer_Defect_Count_per_slot",
                "Nuisance_Count_per_slot",
                "False_Defect_Count_per_slot",
            ]
            if col in filtered_prediction.columns
        ]
        base_cols = [
            "Lot Name",
            "Predicted_Risk",
            "Total_Risk_Score",
            "Severity_Score",
            "Killer_Defect_Count",
            "Total_Count",
            "Killer_Defect_Proportion",
            "Score_Killer",
            "Score_Nuisance",
            "Score_False",
        ]
        top_df = filtered_prediction.nlargest(
            top_n,
            "Predicted_Risk",
        )[base_cols + per_slot_cols + component_cols]
        render_top_lots(top_df, warning_threshold, severity_threshold)
        st.caption(
            "ëª©ë¡ì€ ì˜ˆì¸¡ ìœ„í—˜ë„ ìˆœìœ¼ë¡œ ì •ë ¬ë©ë‹ˆë‹¤. ì‹¤ì œ ê°’ê³¼ ì°¨ì´ë¥¼ í•¨ê»˜ í™•ì¸í•œ ë’¤, ê´€ì‹¬ Lotì„ ì„ íƒí•´ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•˜ì„¸ìš”."
        )

        st.markdown("#### ìœ„í—˜ë„ vs ì‹¬ê°ë„")
        size_options = {
            "í‚¬ëŸ¬ ê²°í•¨ ë¹„ìœ¨": "Killer ê²°í•¨ ë¹„ìœ¨",
            "ì „ì²´ ê²°í•¨ ìˆ˜": "Total_Count",
            "í‚¬ëŸ¬ ê²°í•¨ ìˆ˜": "Killer_Defect_Count",
            "ì‹¬ê°ë„ ì ìˆ˜": "Severity_Score",
        }
        size_mapping = {
            "í‚¬ëŸ¬ ê²°í•¨ ë¹„ìœ¨": "Killer_Defect_Proportion",
            "ì „ì²´ ê²°í•¨ ìˆ˜": "Total_Count",
            "í‚¬ëŸ¬ ê²°í•¨ ìˆ˜": "Killer_Defect_Count",
            "ì‹¬ê°ë„ ì ìˆ˜": "Severity_Score",
        }
        selected_size_label = st.selectbox(
            "ë²„ë¸” í¬ê¸° ê¸°ì¤€",
            list(size_options.keys()),
            index=0,
        )
        render_risk_quadrant(
            filtered_prediction,
            size_metric=size_mapping[selected_size_label],
        )
        st.caption(
            "Xì¶•=ì‹¤ì œ ìœ„í—˜ë„, Yì¶•=ì‹¬ê°ë„, ìƒ‰ìƒ=ì˜ˆì¸¡ ìœ„í—˜ë„, ë²„ë¸” í¬ê¸°=ì„ íƒí•œ ê¸°ì¤€ì…ë‹ˆë‹¤. "
            "í¬ê¸° ê¸°ì¤€ì„ ë°”ê¾¸ë©´ íŠ¹ì • ê³µì • ë˜ëŠ” Lotì˜ ê²½í–¥ì„ ë‹¤ë¥¸ ê´€ì ì—ì„œ ë¹„êµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        )

    with tabs[1]:
        layout_left, layout_right = st.columns([3, 2], gap="large")
        with layout_left:
            lot_selection_df = filtered_prediction[
                ["Lot Name", "Predicted_Risk", "Total_Risk_Score", "Severity_Score"]
            ].copy()
            severity_series = filtered_prediction.get("Severity_Score")
            if severity_series is None:
                severity_series = pd.Series(0, index=filtered_prediction.index, dtype=float)
            primary_warning_mask = filtered_prediction["Predicted_Risk"] >= warning_threshold
            secondary_warning_mask = primary_warning_mask & (
                severity_series >= severity_threshold
            )
            lot_selection_df["Primary_Warning"] = primary_warning_mask.values
            lot_selection_df["Secondary_Warning"] = secondary_warning_mask.values

            warning_only_df = lot_selection_df[lot_selection_df["Primary_Warning"]].copy()
            if warning_only_df.empty:
                st.info("í˜„ì¬ ê²½ê³  ì„ê³„ê°’ì„ ë§Œì¡±í•˜ëŠ” Lotì´ ì—†ìŠµë‹ˆë‹¤. ì „ì²´ Lot ëª©ë¡ì„ í‘œì‹œí•©ë‹ˆë‹¤.")
                warning_only_df = lot_selection_df.copy()
            lot_selection_df = warning_only_df

            if not lot_selection_df.empty:
                def _format_lot_label(row: pd.Series) -> str:
                    warning_badge = "2ì°¨ ê²½ê³ " if row["Secondary_Warning"] else "1ì°¨ ê²½ê³ "
                    return (
                        f"{row['Lot Name']} | ìœ„í—˜ë„ {row['Total_Risk_Score']:.2f} | "
                        f"ì‹¬ê°ë„ {row['Severity_Score']:.2f} | {warning_badge}"
                    )

                lot_selection_df["Lot_Label"] = lot_selection_df.apply(
                    _format_lot_label,
                    axis=1,
                )
                lot_options = lot_selection_df.sort_values(
                    ["Secondary_Warning", "Predicted_Risk", "Severity_Score"],
                    ascending=[False, False, False],
                )
                lot_names = lot_options["Lot Name"].tolist()
                lot_labels = lot_options["Lot_Label"].tolist()
            else:
                lot_names = []
                lot_labels = []
            selected_lot = st.selectbox(
                "Lot ì„ íƒ",
                lot_labels if lot_labels else lot_names,
                index=0 if lot_names else None,
            )
            if not selected_lot:
                st.info("í‘œì‹œí•  Lot ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return
            selected_lot = (
                lot_names[lot_labels.index(selected_lot)]
                if lot_labels
                else selected_lot
            )
            render_lot_detail(
                filtered_prediction,
                filtered_labelled,
                warning_threshold,
                severity_threshold,
                selected_lot,
            )
        with layout_right:
            st.markdown("#### ì›¨ì´í¼ë§µ")
            lot_rows = filtered_labelled[
                filtered_labelled["Lot Name"] == selected_lot
            ].copy()
            _render_wafer_map(lot_rows, width=380, height=420)

    with tabs[2]:
        st.markdown("### ì˜¨í†¨ë¡œì§€ ê¸°ë°˜ ê³µì • ìš°ì„ ìˆœìœ„")
        render_process_priority(
            filtered_priority,
            ontology,
            hotspot_detail=hotspot_detail,
        )


if __name__ == "__main__":
    main()


